{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef2fb29-27a2-4dc8-9344-7a531a66d4e3",
   "metadata": {},
   "source": [
    "# RAG with an Agent\n",
    "* We will build a basic agent for doing retrieval when necessary and also holding a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b061f3d-6e6a-4c3e-9daf-856597af46c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f66f7d",
   "metadata": {},
   "source": [
    "#### **Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d26793-6f3b-4e4e-9473-6c34676d9fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7af37f",
   "metadata": {},
   "source": [
    "#### **Retreiver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c72246-cd97-4b0a-9951-0ca13640b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fea90d-7057-4df3-a5ff-4b396a01fc4b",
   "metadata": {},
   "source": [
    "#### **Retriever as Tool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0801524f-aafb-4709-a1e0-566b5d7b0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"llm_powered_autonomous_agents\",\n",
    "    \"Blog post about LLM Powered Autonomous Agents.\",\n",
    ")\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d84e166-7851-42c7-9a5c-7a00e20500df",
   "metadata": {},
   "source": [
    "#### **Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96f97264-7720-4167-b349-b84721931fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        SystemMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(\n",
    "                input_variables=[], template=\"You are a helpful assistant\"\n",
    "            )\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "        HumanMessagePromptTemplate(\n",
    "            prompt=PromptTemplate(input_variables=[\"input\"], template=\"{input}\")\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b255a88-ad72-4e5f-8ba2-fa28db17bd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "066f5f34-e8b9-473a-ab87-ed74c90c0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac2b23b2-a703-45b0-938b-5a611ed7f2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `llm_powered_autonomous_agents` with `{'query': 'approaches to Task Decomposition'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\n",
      "Self-Reflection#\n",
      "\n",
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "\n",
      "Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
      "The system comprises of 4 stages:\n",
      "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
      "Instruction:\n",
      "\n",
      "The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\u001b[0m\u001b[32;1m\u001b[1;3mTask decomposition can be approached in several ways, particularly when utilizing Large Language Models (LLMs) and autonomous agents. Here are some key approaches:\n",
      "\n",
      "1. **Simple Prompting**: This involves using straightforward prompts to guide the LLM in breaking down tasks. Examples include asking for \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\"\n",
      "\n",
      "2. **Task-Specific Instructions**: This method uses specific instructions tailored to the task at hand. For instance, prompting the LLM with \"Write a story outline\" for writing a novel.\n",
      "\n",
      "3. **Human Inputs**: Incorporating human feedback and insights can also aid in task decomposition, allowing for a more nuanced understanding of the task requirements.\n",
      "\n",
      "4. **LLM+P Approach**: This approach combines LLMs with classical planning techniques. It involves:\n",
      "   - Translating the task into a Planning Domain Definition Language (PDDL) format.\n",
      "   - Using a classical planner to generate a plan based on the PDDL.\n",
      "   - Translating the plan back into natural language. This method is particularly useful in robotic setups where domain-specific PDDL and planners are available.\n",
      "\n",
      "5. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" enhancing its ability to decompose complex tasks into smaller, manageable steps. It also provides insight into the model's reasoning process.\n",
      "\n",
      "6. **Tree of Thoughts**: An extension of CoT, this method explores multiple reasoning possibilities at each step. It decomposes the problem into various thought steps and generates multiple thoughts per step, creating a tree structure. The search process can utilize breadth-first search (BFS) or depth-first search (DFS), with each state evaluated by a classifier or through majority voting.\n",
      "\n",
      "These approaches can be combined or used independently depending on the complexity of the task and the capabilities of the LLM or autonomous agent being employed.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the approaches to Task Decomposition?',\n",
       " 'output': 'Task decomposition can be approached in several ways, particularly when utilizing Large Language Models (LLMs) and autonomous agents. Here are some key approaches:\\n\\n1. **Simple Prompting**: This involves using straightforward prompts to guide the LLM in breaking down tasks. Examples include asking for \"Steps for XYZ\" or \"What are the subgoals for achieving XYZ?\"\\n\\n2. **Task-Specific Instructions**: This method uses specific instructions tailored to the task at hand. For instance, prompting the LLM with \"Write a story outline\" for writing a novel.\\n\\n3. **Human Inputs**: Incorporating human feedback and insights can also aid in task decomposition, allowing for a more nuanced understanding of the task requirements.\\n\\n4. **LLM+P Approach**: This approach combines LLMs with classical planning techniques. It involves:\\n   - Translating the task into a Planning Domain Definition Language (PDDL) format.\\n   - Using a classical planner to generate a plan based on the PDDL.\\n   - Translating the plan back into natural language. This method is particularly useful in robotic setups where domain-specific PDDL and planners are available.\\n\\n5. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" enhancing its ability to decompose complex tasks into smaller, manageable steps. It also provides insight into the model\\'s reasoning process.\\n\\n6. **Tree of Thoughts**: An extension of CoT, this method explores multiple reasoning possibilities at each step. It decomposes the problem into various thought steps and generates multiple thoughts per step, creating a tree structure. The search process can utilize breadth-first search (BFS) or depth-first search (DFS), with each state evaluated by a classifier or through majority voting.\\n\\nThese approaches can be combined or used independently depending on the complexity of the task and the capabilities of the LLM or autonomous agent being employed.'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# question=\"hi, im Gus\"\n",
    "question=\"What are the approaches to Task Decomposition?\"\n",
    "\n",
    "result = agent_executor.invoke({\"input\": question})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9f21766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI don't have access to personal information about users unless it has been shared with me in the course of our conversation. Therefore, I don't know your name. If you'd like to share it, feel free!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name?',\n",
       " 'output': \"I don't have access to personal information about users unless it has been shared with me in the course of our conversation. Therefore, I don't know your name. If you'd like to share it, feel free!\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = agent_executor.invoke({\"input\": 'What is my name?'})\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dedee1",
   "metadata": {},
   "source": [
    "#### **Adding in Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ed2b8cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "963a66ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history = RunnableWithMessageHistory(\n",
    "    agent_executor,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0e48de19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHi Gus! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'hi! my name is Gus',\n",
       " 'chat_history': [],\n",
       " 'output': 'Hi Gus! How can I assist you today?'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"hi! my name is Gus\"},\n",
    "    config={\"configurable\": {\"session_id\": \"any\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a40f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"What are the approaches to Task Decomposition?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"any\"}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8be22944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Gus! How can I help you today, Gus?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Whats my name?',\n",
       " 'chat_history': [HumanMessage(content='hi! my name is Gus', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Hi Gus! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is Gus! How can I help you today, Gus?'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we pass in an empty list of messages for chat_history because it is the first message in the chat\n",
    "agent_with_chat_history.invoke(\n",
    "    {\"input\": \"Whats my name?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"any\"}},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
